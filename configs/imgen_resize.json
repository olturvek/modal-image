{
  "3": {
    "inputs": {
      "seed": 974992643325973,
      "steps": 30,
      "cfg": 4,
      "sampler_name": "dpmpp_sde_gpu",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "14",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "untitled_pony.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "5": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": "score_9, score_8_up, score_7_up, mayafoxx, looking at viewer, sfw, long brown hair, detailed eyes, detailed beautiful face, skinny, \n\nlying on bed, pink bed sheets, velvet bed sheets, from above, selfie, gray hoodie, tousled hair, cute expression, detailed background, white bed, depth of field, modern design\n\nBREAK \n\nnatural light, amateur light, harsh light, underexposed, amateur photo, film grain, selfmade, Fujifilm XT3, hyper realistic, photorealistic, high detailed skin, skin pores, imperfect skin, real skin texture, Goosebump skin",
      "clip": [
        "12",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "nude, text, blurry, extra limbs, watermark, anime, 3d, cartoon, plastic, animated, deformed limbs, bad hands, extra fingers, wonky eyes,  warm light, analogue, blurry eyes, ugly, manly, signs, emojis, (underage, child)",
      "clip": [
        "12",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "11": {
    "inputs": {
      "lora_name": "mayafoxx_SDXL-000002-e750.safetensors",
      "strength_model": 0.8000000000000002,
      "strength_clip": 1.0000000000000002,
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "12": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "14": {
    "inputs": {
      "lora_name": "perfect_hands.safetensors",
      "strength_model": 0.8000000000000002,
      "strength_clip": 1.0000000000000002,
      "model": [
        "18",
        0
      ],
      "clip": [
        "18",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "18": {
    "inputs": {
      "lora_name": "RealSkin_xxXL_v1.safetensors",
      "strength_model": 3.0000000000000004,
      "strength_clip": 1.0000000000000002,
      "model": [
        "31",
        0
      ],
      "clip": [
        "31",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "28": {
    "inputs": {
      "model_name": "4x_foolhardy_Remacri.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "29": {
    "inputs": {
      "upscale_model": [
        "28",
        0
      ],
      "image": [
        "8",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "30": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.2500000000000002,
      "image": [
        "29",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "31": {
    "inputs": {
      "lora_name": "amateur_slider.safetensors",
      "strength_model": 0.5000000000000001,
      "strength_clip": 1.0000000000000002,
      "model": [
        "11",
        0
      ],
      "clip": [
        "11",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "32": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "37",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "37": {
    "inputs": {
      "method": "nearest",
      "image": [
        "30",
        0
      ],
      "width": [
        "38",
        0
      ],
      "height": [
        "38",
        0
      ]
    },
    "class_type": "ImageResize",
    "_meta": {
      "title": "Image Resize"
    }
  },
  "38": {
    "inputs": {
      "value": 2048
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "Int"
    }
  }
}